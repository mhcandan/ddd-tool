# DDD Tool — Usage Guide for Claude

This guide teaches you how to create and manage a DDD (Domain-Driven Design) project using the DDD Tool + Claude Code terminal workflow. You will write YAML spec files that the DDD Tool reads, and use `/ddd-implement` to generate implementation code.

---

## 1. Project Structure

A DDD project has this directory layout:

```
my-project/
  ddd-project.json              # Project config (domains list)
  specs/
    system.yaml                  # Tech stack, project identity
    architecture.yaml            # Conventions, infrastructure, API design
    config.yaml                  # Environment variable schema
    system-layout.yaml           # L1 canvas positions (auto-managed by DDD Tool)
    shared/
      errors.yaml                # Error codes with HTTP status mappings
    schemas/
      _base.yaml                 # Base model (id, timestamps, soft delete)
      {model}.yaml               # Data model definitions
    domains/
      {domain-id}/
        domain.yaml              # Domain config: flows, events, layout
        flows/
          {flow-id}.yaml         # Flow spec: trigger, nodes, connections
  .ddd/
    mapping.yaml                 # Implementation tracking (specHash, files)
    memory/                      # Project memory layers
    autosave/                    # Crash recovery
    reconciliations/             # Reconciliation reports
  generated/                     # Generator outputs (OpenAPI, Dockerfile, etc.)
  src/                           # Implementation code (generated by Claude Code)
```

---

## 2. ddd-project.json

The root project config. Lists all domains:

```json
{
  "domains": [
    { "name": "Users", "description": "User management and authentication" },
    { "name": "Billing", "description": "Subscriptions and payments" },
    { "name": "Support", "description": "Customer support tickets" }
  ]
}
```

Domain IDs are derived from names: lowercase, spaces replaced with hyphens (e.g., "Users" -> "users").

---

## 3. Domain YAML

**Path:** `specs/domains/{domain-id}/domain.yaml`

```yaml
name: Users
description: User management and authentication
flows:
  - id: user-register
    name: User Registration
    description: Register a new user account
    type: traditional
  - id: user-login
    name: User Login
    description: Authenticate and issue JWT
    type: traditional
publishes_events:
  - event: UserRegistered
    schema: User
    from_flow: user-register
    description: Fired after successful registration
  - event: UserLoggedIn
    from_flow: user-login
consumes_events: []
layout:
  flows:
    user-register: { x: 100, y: 100 }
    user-login: { x: 100, y: 300 }
  portals: {}
```

### Domain Fields

| Field | Type | Description |
|-------|------|-------------|
| `name` | string | Display name |
| `description` | string? | What this domain handles |
| `flows` | DomainFlowEntry[] | List of flows in this domain |
| `publishes_events` | EventWiring[] | Events this domain emits |
| `consumes_events` | EventWiring[] | Events this domain listens to |
| `layout` | DomainLayout | Canvas positions (managed by DDD Tool) |

### DomainFlowEntry

| Field | Type | Description |
|-------|------|-------------|
| `id` | string | Unique flow ID (kebab-case) |
| `name` | string | Display name |
| `description` | string? | What this flow does |
| `type` | `'traditional' \| 'agent'` | Flow type |

### EventWiring

| Field | Type | Description |
|-------|------|-------------|
| `event` | string | Event name (e.g., UserRegistered) |
| `schema` | string? | Data schema reference |
| `from_flow` | string? | Which flow publishes it |
| `handled_by_flow` | string? | Which flow consumes it |
| `description` | string? | What this event means |

---

## 4. Supplementary Spec Files

These files are **NOT read by the DDD Tool UI**. They are context files that `/ddd-implement` reads to generate correct implementation code. Create them at the root of `specs/` so Claude Code can reference them during implementation.

### 4.1 system.yaml

**Path:** `specs/system.yaml`

Project identity and tech stack choices:

```yaml
name: my-project
version: "1.0.0"
description: Brief description of the project

tech_stack:
  language: TypeScript
  runtime: Node.js 20
  framework: Express 4
  database: PostgreSQL 16
  orm: Prisma
  cache: Redis 7
  queue: BullMQ
  auth: JWT + bcrypt

environments:
  - name: development
    url: http://localhost:3000
  - name: staging
    url: https://staging.example.com
  - name: production
    url: https://api.example.com
```

### 4.2 architecture.yaml

**Path:** `specs/architecture.yaml`

Project conventions, infrastructure, and API design standards:

```yaml
project_structure:
  src/
    routes/: Express route handlers
    services/: Business logic
    models/: Prisma models
    middleware/: Auth, validation, error handling
    utils/: Shared utilities
    types/: TypeScript type definitions
  tests/
    unit/: Unit tests
    integration/: Integration tests

naming_conventions:
  files: kebab-case
  classes: PascalCase
  functions: camelCase
  variables: camelCase
  constants: UPPER_SNAKE_CASE
  database_tables: snake_case
  api_endpoints: kebab-case

dependencies:
  runtime:
    - express: "^4.18"
    - prisma: "^5.0"
    - zod: "^3.22"
    - jsonwebtoken: "^9.0"
  dev:
    - vitest: "^1.0"
    - supertest: "^6.3"
    - typescript: "^5.3"

infrastructure:
  containerization: Docker
  orchestration: Kubernetes
  ci_cd: GitHub Actions
  monitoring: Prometheus + Grafana
  logging: Pino structured JSON

api_design:
  versioning: URL prefix (/api/v1)
  pagination:
    style: cursor
    default_limit: 20
    max_limit: 100
    response_format:
      data: "array of items"
      cursor: "next page cursor"
      has_more: "boolean"
  filtering:
    style: query parameters
    operators: "eq, ne, gt, gte, lt, lte, in, like"
    example: "?status=active&created_at[gte]=2025-01-01"
  error_format:
    error:
      code: "ERROR_CODE"
      message: "Human-readable message"
      details: "Optional additional context"

testing:
  framework: vitest
  runner: "npx vitest run"
  coverage_target: 80%
  patterns:
    unit: "tests/unit/**/*.test.ts"
    integration: "tests/integration/**/*.test.ts"

deployment:
  strategy: rolling update
  health_check: /health
  readiness_check: /ready
```

### 4.3 config.yaml

**Path:** `specs/config.yaml`

Environment variable schema — defines what env vars the project needs:

```yaml
required:
  - name: DATABASE_URL
    type: string
    description: PostgreSQL connection string
    example: "postgresql://user:pass@localhost:5432/mydb"
    sensitive: true

  - name: JWT_SECRET
    type: string
    description: Secret key for JWT signing
    sensitive: true

  - name: REDIS_URL
    type: string
    description: Redis connection string
    example: "redis://localhost:6379"

optional:
  - name: PORT
    type: number
    default: 3000
    description: Server port

  - name: LOG_LEVEL
    type: string
    default: "info"
    description: Logging level (debug, info, warn, error)

  - name: CORS_ORIGINS
    type: string
    default: "*"
    description: Comma-separated allowed origins

  - name: RATE_LIMIT_RPM
    type: number
    default: 60
    description: Requests per minute per IP
```

### 4.4 errors.yaml

**Path:** `specs/shared/errors.yaml`

Structured error codes with HTTP status mappings:

```yaml
errors:
  VALIDATION_ERROR:
    http_status: 400
    message_template: "Validation failed: {details}"
    log_level: warn

  UNAUTHORIZED:
    http_status: 401
    message_template: "Authentication required"
    log_level: warn

  FORBIDDEN:
    http_status: 403
    message_template: "Insufficient permissions"
    log_level: warn

  NOT_FOUND:
    http_status: 404
    message_template: "{resource} not found"
    log_level: info

  DUPLICATE_ENTRY:
    http_status: 409
    message_template: "{resource} already exists"
    log_level: warn

  RATE_LIMITED:
    http_status: 429
    message_template: "Too many requests, try again in {retry_after}s"
    log_level: warn

  INTERNAL_ERROR:
    http_status: 500
    message_template: "An unexpected error occurred"
    log_level: error

  SERVICE_UNAVAILABLE:
    http_status: 503
    message_template: "{service} is temporarily unavailable"
    log_level: error
```

### 4.5 Schema Definitions

**Path:** `specs/schemas/{model}.yaml`

Data model definitions used across flows. Start with a base model:

**`specs/schemas/_base.yaml`** — fields inherited by all models:

```yaml
name: Base
description: Common fields for all models
fields:
  - name: id
    type: uuid
    required: true
    description: Primary key (auto-generated)
  - name: created_at
    type: datetime
    required: true
    description: Creation timestamp (auto-set)
  - name: updated_at
    type: datetime
    required: true
    description: Last update timestamp (auto-set)
  - name: deleted_at
    type: datetime
    required: false
    description: Soft delete timestamp (null = active)
```

**`specs/schemas/user.yaml`** — example model:

```yaml
name: User
description: User account
inherits: _base
fields:
  - name: email
    type: string
    required: true
    format: email
    constraints:
      unique: true
      max_length: 255
  - name: password_hash
    type: string
    required: true
    constraints:
      max_length: 255
  - name: name
    type: string
    required: true
    constraints:
      max_length: 100
  - name: role
    type: enum
    required: true
    values: [user, admin]
    default: user
  - name: is_verified
    type: boolean
    required: true
    default: false
  - name: last_login_at
    type: datetime
    required: false

indexes:
  - fields: [email]
    unique: true
  - fields: [role, created_at]

relationships:
  - name: orders
    type: has_many
    target: Order
    foreign_key: user_id
```

---

## 5. Flow YAML

**Path:** `specs/domains/{domain-id}/flows/{flow-id}.yaml`

This is the core spec file. It defines the entire flow graph.

```yaml
flow:
  id: user-register
  name: User Registration
  type: traditional
  domain: users
  description: Register a new user account

trigger:
  id: trigger-abc123
  type: trigger
  position: { x: 250, y: 50 }
  connections:
    - targetNodeId: input-def456
  spec:
    event: HTTP POST /auth/register
    source: API Gateway
    description: Registration request received
  label: API Request

nodes:
  - id: input-def456
    type: input
    position: { x: 250, y: 170 }
    connections:
      - targetNodeId: process-ghi789
        sourceHandle: "valid"
      - targetNodeId: terminal-validation-error
        sourceHandle: "invalid"
    spec:
      fields:
        - name: email
          type: string
          required: true
        - name: password
          type: string
          required: true
        - name: name
          type: string
          required: true
      validation: "Email format, password min 8 chars"
      description: Registration form data
    label: Registration Form

  - id: process-ghi789
    type: process
    position: { x: 250, y: 300 }
    connections:
      - targetNodeId: decision-jkl012
    spec:
      action: Hash password and create user record
      service: UserService.register
      description: Create user in database
    label: Create User

  - id: decision-jkl012
    type: decision
    position: { x: 250, y: 430 }
    connections:
      - targetNodeId: terminal-success
        sourceHandle: "true"
      - targetNodeId: terminal-error
        sourceHandle: "false"
    spec:
      condition: user.exists?
      trueLabel: "No (new user)"
      falseLabel: "Yes (duplicate)"
      description: Check if email already registered
    label: Email Exists?

  - id: terminal-success
    type: terminal
    position: { x: 150, y: 560 }
    connections: []
    spec:
      outcome: success
      description: Return user object with JWT token
      status: 201
      body:
        message: "User registered successfully"
        user: "$.user"
        token: "$.jwt_token"
    label: Success

  - id: terminal-error
    type: terminal
    position: { x: 400, y: 560 }
    connections: []
    spec:
      outcome: error
      description: Return 409 Conflict
      status: 409
      body:
        error: "DUPLICATE_ENTRY"
        message: "Email already registered"
    label: Duplicate Email

  - id: terminal-validation-error
    type: terminal
    position: { x: 450, y: 300 }
    connections: []
    spec:
      outcome: error
      description: Return 400 Validation Error
      status: 400
      body:
        error: "VALIDATION_ERROR"
        message: "$.validation_errors"
    label: Invalid Input

metadata:
  created: "2025-01-10T10:00:00Z"
  modified: "2025-01-15T14:30:00Z"
```

### FlowDocument Structure

| Field | Type | Description |
|-------|------|-------------|
| `flow` | object | Flow metadata |
| `flow.id` | string | Unique flow ID |
| `flow.name` | string | Display name |
| `flow.type` | `'traditional' \| 'agent'` | Flow category |
| `flow.domain` | string | Parent domain ID |
| `flow.description` | string? | What this flow does |
| `trigger` | DddFlowNode | The entry point node |
| `nodes` | DddFlowNode[] | All other nodes |
| `metadata` | object | `{ created, modified }` ISO timestamps |

### DddFlowNode (Common Fields)

Every node has:

| Field | Type | Description |
|-------|------|-------------|
| `id` | string | Unique node ID |
| `type` | DddNodeType | One of the 19 node types |
| `position` | `{ x, y }` | Canvas position |
| `connections` | Array | List of `{ targetNodeId, sourceHandle?, targetHandle? }` |
| `spec` | object | Type-specific configuration (see below) |
| `label` | string | Display name on canvas |
| `observability` | object? | Logging/metrics/tracing config |
| `security` | object? | Auth/rate-limiting/encryption config |

---

## 6. All Node Types and Their Specs

### 6.1 Traditional Nodes

#### trigger
The entry point of every flow. Exactly one per flow.

| Spec Field | Type | Description |
|------------|------|-------------|
| `event` | string | What triggers the flow (see conventions below) |
| `source` | string | Where the trigger comes from (e.g., "API Gateway") |
| `description` | string | Details |

**Trigger type conventions** — use these patterns in the `event` field to communicate trigger semantics:

```yaml
# HTTP trigger — "HTTP {METHOD} {path}"
spec:
  event: "HTTP POST /api/users/register"
  source: API Gateway
  description: User registration endpoint

# Scheduled trigger — "cron {expression}"
spec:
  event: "cron */30 * * * *"
  source: Scheduler
  description: Runs every 30 minutes

# Event trigger — "event:{EventName}"
spec:
  event: "event:UserRegistered"
  source: Message Bus
  description: Triggered when a user registers

# Manual trigger
spec:
  event: "manual"
  source: Admin Dashboard
  description: Triggered manually by admin

# Webhook trigger — "webhook {path}"
spec:
  event: "webhook /stripe/events"
  source: Stripe
  description: Stripe webhook callback
```

#### input
Validates incoming data. Has two output handles: `valid` and `invalid`. Always specify `sourceHandle` on connections.

| Spec Field | Type | Description |
|------------|------|-------------|
| `fields` | `Array<{ name, type, required? }>` | Field definitions |
| `validation` | string | Validation rules/regex |
| `description` | string | What this input represents |

**Conditional required fields** — use the `validation` string to express conditional rules:

```yaml
spec:
  fields:
    - name: action
      type: string
      required: true
    - name: reason
      type: string
      required: false
  validation: "required_if: action == 'reject' then reason is required"
  description: Review decision
```

#### process
Business logic step.

| Spec Field | Type | Description |
|------------|------|-------------|
| `action` | string | What this step does |
| `service` | string | Service/function to call |
| `description` | string | Details |

#### decision
Branching point. Has two output handles: `true` and `false`. Connections must use `sourceHandle: "true"` or `sourceHandle: "false"`.

| Spec Field | Type | Description |
|------------|------|-------------|
| `condition` | string | The condition to evaluate |
| `trueLabel` | string | Label for the true branch |
| `falseLabel` | string | Label for the false branch |
| `description` | string | Details |

#### terminal
End state. Must have zero outgoing connections. Use custom fields `status` and `body` to specify the HTTP response for implementation.

| Spec Field | Type | Description |
|------------|------|-------------|
| `outcome` | string | Result (e.g., "success", "error", "timeout") |
| `description` | string | What happens at this endpoint |
| `status` | number? | HTTP status code (custom field for implementation) |
| `body` | object? | Response body shape (custom field for implementation) |

**Terminal response examples:**

```yaml
# Success response with data
spec:
  outcome: success
  description: Return user object with JWT token
  status: 201
  body:
    message: "User registered successfully"
    user: "$.user"
    token: "$.jwt_token"

# Error response with error code
spec:
  outcome: error
  description: Return 409 Conflict
  status: 409
  body:
    error: "DUPLICATE_ENTRY"
    message: "Email already registered"

# Empty success (no body)
spec:
  outcome: success
  description: Delete completed
  status: 204
```

### 6.2 Extended Traditional Nodes

#### data_store
Database operation. Use `sourceHandle` values `"success"` and `"error"` on connections for success/error routing.

| Spec Field | Type | Values |
|------------|------|--------|
| `operation` | string | `'create' \| 'read' \| 'update' \| 'delete'` |
| `model` | string | Entity/table name (e.g., "User") |
| `data` | `Record<string, string>` | Fields to write (for create/update) |
| `query` | `Record<string, string>` | Query conditions (for read/update/delete) |
| `description` | string | Details |
| `pagination` | object? | Pagination config (custom field, for list operations) |
| `sort` | object? | Sort config (custom field, for list operations) |

**Pagination and sorting** — for read operations that return lists, add pagination custom fields:

```yaml
spec:
  operation: read
  model: Product
  query:
    status: active
  pagination:
    style: cursor
    default_limit: 20
    max_limit: 100
  sort:
    default: "created_at:desc"
    allowed: ["created_at", "name", "price"]
  description: List active products with pagination
```

#### service_call
External API call. Use `sourceHandle` values `"success"` and `"error"` on connections for success/error routing. The `error_mapping` field maps HTTP status codes to error code strings that `/ddd-implement` will use in error handlers.

| Spec Field | Type | Values |
|------------|------|--------|
| `method` | string | `'GET' \| 'POST' \| 'PUT' \| 'PATCH' \| 'DELETE'` |
| `url` | string | API endpoint URL |
| `headers` | `Record<string, string>` | HTTP headers |
| `body` | `Record<string, unknown>` | Request body |
| `timeout_ms` | number | Request timeout |
| `retry` | object | `{ max_attempts?, backoff_ms? }` |
| `error_mapping` | `Record<string, string>` | Status code to error code mapping |
| `description` | string | Details |

**Error mapping example:**

```yaml
spec:
  method: POST
  url: "https://payment.internal/api/charge"
  error_mapping:
    "400": "INVALID_PAYMENT_DATA"
    "402": "PAYMENT_DECLINED"
    "409": "DUPLICATE_CHARGE"
    "503": "PAYMENT_SERVICE_UNAVAILABLE"
  description: Charge customer payment method
```

#### event
Publish or subscribe to an event.

| Spec Field | Type | Values |
|------------|------|--------|
| `direction` | string | `'emit' \| 'consume'` |
| `event_name` | string | Event identifier |
| `payload` | `Record<string, unknown>` | Event data shape |
| `async` | boolean | Fire-and-forget? |
| `description` | string | Details |

#### loop
Iterate over a collection. Has two output paths: `"body"` for the loop body and `"done"` for after the loop completes. Use `sourceHandle` values on connections.

| Spec Field | Type | Description |
|------------|------|-------------|
| `collection` | string | What to iterate (e.g., "users", "$.items") |
| `iterator` | string | Iterator variable name |
| `break_condition` | string | When to stop early |
| `description` | string | Details |

#### parallel
Run branches concurrently. The `branches` field is descriptive (documents what each branch does). Actual parallel paths are defined by connections using `sourceHandle: "branch-0"`, `"branch-1"`, etc. Use `sourceHandle: "done"` for the join/continuation node.

| Spec Field | Type | Values |
|------------|------|--------|
| `branches` | string[] | Branch names/descriptions |
| `join` | string | `'all' \| 'any' \| 'n_of'` |
| `join_count` | number | Required if join is `n_of` |
| `timeout_ms` | number | Max wait time |
| `description` | string | Details |

#### sub_flow
Reference another flow.

| Spec Field | Type | Description |
|------------|------|-------------|
| `flow_ref` | string | Target flow in `domain/flow-id` format |
| `input_mapping` | `Record<string, string>` | Input parameter mapping |
| `output_mapping` | `Record<string, string>` | Output parameter mapping |
| `description` | string | Details |

#### llm_call
Single LLM invocation (not an agent loop).

| Spec Field | Type | Description |
|------------|------|-------------|
| `model` | string | Model ID (e.g., "claude-sonnet") |
| `system_prompt` | string | System instructions |
| `prompt_template` | string | Prompt with `{variable}` placeholders |
| `temperature` | number | 0.0 - 1.0 |
| `max_tokens` | number | Max output tokens |
| `structured_output` | `Record<string, unknown>` | Expected output schema |
| `retry` | object | `{ max_attempts?, backoff_ms? }` |
| `description` | string | Details |

### 6.3 Agent Nodes (for `type: agent` flows)

#### agent_loop
LLM agent with tools in a loop.

| Spec Field | Type | Values |
|------------|------|--------|
| `model` | string | Model ID |
| `system_prompt` | string | Agent instructions |
| `max_iterations` | number | Max tool-use loops |
| `temperature` | number | 0.0 - 1.0 |
| `stop_conditions` | string[] | When to stop (e.g., "answer_provided") |
| `tools` | ToolDefinition[] | Available tools (see below) |
| `memory` | MemoryStoreDefinition[] | Memory stores (see below) |
| `on_max_iterations` | string | `'escalate' \| 'respond' \| 'error'` |

**ToolDefinition:**

| Field | Type | Description |
|-------|------|-------------|
| `id` | string | Unique tool ID |
| `name` | string | Function name |
| `description` | string | What the tool does |
| `parameters` | string | JSON schema of parameters |
| `implementation` | string? | Implementation reference |
| `is_terminal` | boolean? | Ends the loop when used |
| `requires_confirmation` | boolean? | Needs human approval |

**MemoryStoreDefinition:**

| Field | Type | Values |
|-------|------|--------|
| `name` | string | Store name |
| `type` | string | `'conversation_history' \| 'vector_store' \| 'key_value'` |
| `max_tokens` | number? | Token limit |
| `strategy` | string? | Eviction strategy (e.g., "sliding_window") |

#### guardrail
Input/output validation for agent flows. Guardrails are **inline and sequential** — data flows through them in order. They are NOT sidecars or parallel watchers. Place them before or after an agent_loop in the connection chain.

| Spec Field | Type | Values |
|------------|------|--------|
| `position` | string | `'input' \| 'output'` |
| `checks` | GuardrailCheck[] | `{ type: string, action: 'block' \| 'warn' \| 'log' }` |
| `on_block` | string | What to do when blocked |

#### human_gate
Asynchronous human approval step for agent workflows. The agent pauses and waits for human review before continuing.

**Important:** `human_gate` is for async agent approval workflows (e.g., "agent proposes resolution, human reviews"). For synchronous HTTP request/response approval patterns (e.g., "admin approves a user request"), use an HTTP trigger + decision node instead. See Section 16 Design Patterns.

| Spec Field | Type | Description |
|------------|------|-------------|
| `notification_channels` | string[] | e.g., ["slack", "email"] |
| `approval_options` | ApprovalOption[] | `{ id, label, description?, requires_input? }` |
| `timeout` | object | `{ duration?: number, action?: 'escalate' \| 'auto_approve' \| 'auto_reject' }` |
| `context_for_human` | string[] | Data to show the human reviewer |

### 6.4 Orchestration Nodes

#### orchestrator
Manages multiple agents.

| Spec Field | Type | Values |
|------------|------|--------|
| `strategy` | string | `'supervisor' \| 'round_robin' \| 'broadcast' \| 'consensus'` |
| `model` | string | Supervisor model |
| `supervisor_prompt` | string | Instructions for the supervisor |
| `agents` | OrchestratorAgent[] | `{ id, flow, specialization?, priority? }` |
| `fallback_chain` | string[] | Fallback agent order |
| `shared_memory` | SharedMemoryEntry[] | `{ name, type, access: 'read_write' \| 'read_only' }` |
| `supervision` | object | `{ monitor_iterations?, intervene_on?: SupervisionRule[] }` |
| `result_merge_strategy` | string | `'last_wins' \| 'best_of' \| 'combine' \| 'supervisor_picks'` |

#### smart_router
Routes to different agents based on rules.

| Spec Field | Type | Description |
|------------|------|-------------|
| `rules` | SmartRouterRule[] | `{ id, condition, route, priority? }` |
| `llm_routing` | object | `{ enabled?, model?, routing_prompt?, confidence_threshold?, routes? }` |
| `fallback_chain` | string[] | Fallback route order |
| `policies` | object | retry, timeout, circuit_breaker configs |

#### handoff
Transfer control between agents.

| Spec Field | Type | Values |
|------------|------|--------|
| `mode` | string | `'transfer' \| 'consult' \| 'collaborate'` |
| `target` | object | `{ flow?, domain? }` |
| `context_transfer` | object | `{ include_types?, max_context_tokens? }` |
| `on_complete` | object | `{ return_to?, merge_strategy? }` |
| `on_failure` | object | `{ action?, timeout? }` |
| `notify_customer` | boolean | Notify the end user? |

#### agent_group
Group of agents working together.

| Spec Field | Type | Description |
|------------|------|-------------|
| `name` | string | Group name |
| `description` | string | What this group does |
| `members` | AgentGroupMember[] | `{ flow, domain? }` |
| `shared_memory` | SharedMemoryEntry[] | Shared state |
| `coordination` | object | `{ communication?, max_active_agents?, selection_strategy?, sticky_session? }` |

---

## 7. Cross-Cutting Concerns (Per-Node)

Every node can optionally have `observability` and `security` configs:

### Observability

```yaml
observability:
  logging:
    level: info          # debug | info | warn | error
    include_input: true
    include_output: false
  metrics:
    enabled: true
    custom_counters:
      - requests
      - errors
  tracing:
    enabled: true
    span_name: node.validate_input
```

### Security

```yaml
security:
  authentication:
    required: true
    methods: [jwt, api_key]
    roles: [admin, user]
  rate_limiting:
    enabled: true
    requests_per_minute: 60
  encryption:
    at_rest: true
    in_transit: true
    pii_fields: [email, ssn]
  audit:
    enabled: true
```

---

## 8. Connection Patterns

Connections define the flow graph. Each connection is `{ targetNodeId, sourceHandle?, targetHandle? }`.

**Convention:** For nodes with multiple output paths, always use `sourceHandle` to label each path. This makes the flow graph unambiguous for both the DDD Tool and `/ddd-implement`.

### Simple connection (one output)
```yaml
connections:
  - targetNodeId: next-node-id
```

### Decision branches (two outputs)
```yaml
connections:
  - targetNodeId: success-node-id
    sourceHandle: "true"
  - targetNodeId: failure-node-id
    sourceHandle: "false"
```

### Input validation branches (valid/invalid)
```yaml
connections:
  - targetNodeId: process-node-id
    sourceHandle: "valid"
  - targetNodeId: error-terminal-id
    sourceHandle: "invalid"
```

### data_store success/error
```yaml
connections:
  - targetNodeId: next-step-id
    sourceHandle: "success"
  - targetNodeId: error-terminal-id
    sourceHandle: "error"
```

### service_call success/error
```yaml
connections:
  - targetNodeId: next-step-id
    sourceHandle: "success"
  - targetNodeId: error-terminal-id
    sourceHandle: "error"
```

### Loop body + after loop
```yaml
connections:
  - targetNodeId: loop-body-node-id
    sourceHandle: "body"
  - targetNodeId: after-loop-node-id
    sourceHandle: "done"
```

### Parallel branches + join
```yaml
# branches field is descriptive (for documentation)
# connections define actual parallel paths
connections:
  - targetNodeId: branch-a-first-node
    sourceHandle: "branch-0"
  - targetNodeId: branch-b-first-node
    sourceHandle: "branch-1"
  - targetNodeId: join-node-id
    sourceHandle: "done"
```

### Smart Router (multiple outputs)
```yaml
connections:
  - targetNodeId: route-a-id
    sourceHandle: "route-a"
  - targetNodeId: route-b-id
    sourceHandle: "route-b"
```

---

## 9. Validation Rules

The DDD Tool enforces these validation rules. Your specs should pass all of them.

### Flow-Level (Error)
- Every flow must have exactly one trigger node
- All paths from trigger must reach a terminal node
- No orphaned (unreachable) nodes
- No circular paths in traditional flows (agents may have cycles)
- Decision nodes must have both true and false branch connections
- Trigger must have an `event` defined
- Input fields must have `type` defined
- Decision must have a `condition` defined

### Flow-Level (Warning)
- Terminal nodes should not have outgoing connections
- Process nodes should have a description or action
- Agent loops should have `max_iterations` and `model` set

### Agent-Specific (Error)
- Agent flow must have at least one `agent_loop` node
- Agent loop must have at least one tool
- Agent loop must have at least one terminal tool (`is_terminal: true`)

### Orchestration (Error)
- Orchestrator must have 2+ agents and a strategy
- Smart Router must have rules defined
- Handoff must have a target flow
- Agent Group must have 2+ members

### Extended Nodes (Error)
- Data Store must have operation and model
- Service Call must have method and URL
- Event must have direction and event_name
- Loop must have collection and iterator
- Parallel must have 2+ branches
- Sub-flow must have flow_ref
- LLM Call must have model

### Domain-Level
- No duplicate flow IDs within a domain

### System-Level
- Events consumed by a domain must be published by some domain
- Events published should be consumed by at least one domain (warning)

The DDD Tool validates event wiring across domains automatically (system-level validation). If a domain consumes an event that no domain publishes, the tool flags it as an error. If a domain publishes an event that nothing consumes, it flags a warning.

---

## 10. Workflow: Creating a DDD Project

### Step 1: Create project files

```bash
mkdir my-project && cd my-project

# Create ddd-project.json
cat > ddd-project.json << 'EOF'
{
  "domains": [
    { "name": "Users", "description": "User management" },
    { "name": "Orders", "description": "Order processing" }
  ]
}
EOF

# Create directory structure
mkdir -p specs/domains/users/flows
mkdir -p specs/domains/orders/flows
mkdir -p specs/shared
mkdir -p specs/schemas
```

### Step 2: Create supplementary spec files

Create `specs/system.yaml`, `specs/architecture.yaml`, `specs/config.yaml`, `specs/shared/errors.yaml`, and schema files in `specs/schemas/`. See Section 4 for formats.

### Step 3: Write domain YAML files

Create `specs/domains/users/domain.yaml` with flows, events, layout.

### Step 4: Write flow YAML files

Create `specs/domains/users/flows/user-register.yaml` with the full flow graph (trigger -> nodes -> terminals).

### Step 5: Open in DDD Tool

Open the project in the DDD Tool to visualize, validate, and refine the specs using the graphical canvas.

### Step 6: Implement with Claude Code

Use the `/ddd-implement` command in a Claude Code terminal to generate implementation code from the specs.

---

## 11. Slash Commands

### /ddd-implement

Generates implementation code from DDD specs.

| Argument | Scope | Example |
|----------|-------|---------|
| `--all` | Entire project | `/ddd-implement --all` |
| `{domain}` | All flows in a domain | `/ddd-implement users` |
| `{domain}/{flow}` | Single flow | `/ddd-implement users/user-register` |
| *(empty)* | Interactive mode | `/ddd-implement` |

**What it does:**
1. Reads `ddd-project.json` and flow YAML specs
2. Reads supplementary specs (system.yaml, architecture.yaml, config.yaml, errors.yaml, schemas/) for implementation context
3. Checks `.ddd/mapping.yaml` for existing implementations
4. Follows the node graph: trigger -> nodes -> terminals
5. Generates code for each node (route handlers, services, DB queries, etc.)
6. Generates tests (happy path, decision branches, error states, input validation)
7. Runs tests and fixes until passing
8. Updates `.ddd/mapping.yaml` with specHash and file list

### /ddd-update

Updates DDD project specs (YAML files) to reflect design changes during development. This is the reverse of `/ddd-implement` — instead of code from specs, it updates specs to match new requirements.

| Argument | Scope | Example |
|----------|-------|---------|
| `{domain}/{flow}` | Update a specific flow spec | `/ddd-update users/user-register` |
| `{domain}` | Update domain config and/or its flows | `/ddd-update users` |
| `--add-flow {domain}` | Add a new flow to a domain | `/ddd-update --add-flow users` |
| `--add-domain` | Add a new domain to the project | `/ddd-update --add-domain` |
| *(empty)* | Interactive mode | `/ddd-update` |

**What it does:**
1. Reads current YAML specs
2. Applies the user's requested changes (add/modify/remove nodes, flows, domains)
3. Maintains spec integrity (valid graph, no orphans, proper connections)
4. Preserves unchanged nodes, IDs, and positions
5. Updates `metadata.modified` timestamp
6. Handles cross-domain event wiring impacts
7. Reports what changed and suggests next steps (Reload DDD Tool, re-implement)

**Typical usage in Session B:**
```
User: "Add rate limiting before the login process"
Claude: /ddd-update users/user-login
  → Updates the flow YAML with a new process node
  → "Reload DDD Tool (Cmd+R) to see changes"
  → "Run /ddd-implement users/user-login to update code"
```

### /ddd-sync

Synchronizes specs with implementation state.

| Argument | What it does |
|----------|-------------|
| *(default)* | Sync mapping.yaml with current implementation state |
| `--discover` | Also discover untracked code and suggest new flow specs |
| `--fix-drift` | Re-implement flows where specs have drifted |
| `--full` | All of the above |

---

## 12. mapping.yaml

**Path:** `.ddd/mapping.yaml`

Tracks what has been implemented:

```yaml
flows:
  users/user-register:
    specHash: a1b2c3d4e5f6...    # SHA-256 of the flow YAML
    implementedAt: "2025-01-15T14:30:00Z"
    files:
      - src/routes/auth.ts
      - src/services/user-service.ts
      - src/models/user.ts
      - tests/routes/auth.test.ts
  users/user-login:
    specHash: f6e5d4c3b2a1...
    implementedAt: "2025-01-16T10:00:00Z"
    files:
      - src/routes/auth.ts
      - src/services/auth-service.ts
```

**Drift detection:** If the specHash no longer matches the flow YAML content, the flow is "stale" and needs re-implementation.

---

## 13. Flow Templates

When creating a flow in the DDD Tool, these templates are available:

### Traditional Templates
| Template | Nodes | Pattern |
|----------|-------|---------|
| REST API Endpoint | 5 | Trigger -> Input -> Process -> Terminal (success/error) |
| CRUD Entity | 6 | Trigger -> Input -> Decision -> Data Store -> Terminal |
| Webhook Handler | 5 | Trigger -> Input -> Process -> Service Call -> Terminal |
| Event Processor | 5 | Trigger -> Event (consume) -> Process -> Event (emit) -> Terminal |

### Agent Templates
| Template | Nodes | Pattern |
|----------|-------|---------|
| RAG Agent | 5 | Guardrail -> Agent Loop (retrieval) -> Guardrail -> Terminal |
| Customer Support Agent | 5 | Guardrail -> Agent Loop (tickets) -> Human Gate -> Terminal |
| Code Review Agent | 3 | Trigger -> Agent Loop (analysis) -> Terminal |
| Data Pipeline Agent | 3 | Trigger -> Agent Loop (ETL) -> Terminal |

---

## 14. Complete Example: E-Commerce Project

### ddd-project.json

```json
{
  "domains": [
    { "name": "Users", "description": "Authentication and user profiles" },
    { "name": "Products", "description": "Product catalog management" },
    { "name": "Orders", "description": "Order processing and fulfillment" },
    { "name": "Notifications", "description": "Email and push notifications" }
  ]
}
```

### specs/system.yaml

```yaml
name: ecommerce-api
version: "1.0.0"
description: E-commerce platform API

tech_stack:
  language: TypeScript
  runtime: Node.js 20
  framework: Express 4
  database: PostgreSQL 16
  orm: Prisma
  cache: Redis 7
  queue: BullMQ
  auth: JWT + bcrypt
```

### specs/shared/errors.yaml

```yaml
errors:
  VALIDATION_ERROR:
    http_status: 400
    message_template: "Validation failed: {details}"
    log_level: warn
  UNAUTHORIZED:
    http_status: 401
    message_template: "Authentication required"
    log_level: warn
  NOT_FOUND:
    http_status: 404
    message_template: "{resource} not found"
    log_level: info
  DUPLICATE_ENTRY:
    http_status: 409
    message_template: "{resource} already exists"
    log_level: warn
  INSUFFICIENT_STOCK:
    http_status: 409
    message_template: "Insufficient stock for {item}"
    log_level: warn
  INTERNAL_ERROR:
    http_status: 500
    message_template: "An unexpected error occurred"
    log_level: error
```

### specs/schemas/user.yaml

```yaml
name: User
description: User account
inherits: _base
fields:
  - name: email
    type: string
    required: true
    format: email
    constraints:
      unique: true
  - name: password_hash
    type: string
    required: true
  - name: name
    type: string
    required: true
  - name: role
    type: enum
    values: [user, admin]
    default: user
indexes:
  - fields: [email]
    unique: true
relationships:
  - name: orders
    type: has_many
    target: Order
    foreign_key: user_id
```

### specs/schemas/order.yaml

```yaml
name: Order
description: Customer order
inherits: _base
fields:
  - name: user_id
    type: uuid
    required: true
  - name: items
    type: json
    required: true
  - name: shipping_address
    type: json
    required: true
  - name: status
    type: enum
    values: [pending, confirmed, shipped, delivered, cancelled]
    default: pending
  - name: total
    type: decimal
    required: true
indexes:
  - fields: [user_id, status]
relationships:
  - name: user
    type: belongs_to
    target: User
    foreign_key: user_id
```

### specs/domains/users/domain.yaml

```yaml
name: Users
description: Authentication and user profiles
flows:
  - id: user-register
    name: User Registration
    type: traditional
  - id: user-login
    name: User Login
    type: traditional
  - id: reset-password
    name: Password Reset
    type: traditional
publishes_events:
  - event: UserRegistered
    from_flow: user-register
    description: New user created
  - event: PasswordResetRequested
    from_flow: reset-password
consumes_events: []
layout:
  flows:
    user-register: { x: 100, y: 100 }
    user-login: { x: 100, y: 300 }
    reset-password: { x: 100, y: 500 }
  portals: {}
```

### specs/domains/orders/domain.yaml

```yaml
name: Orders
description: Order processing and fulfillment
flows:
  - id: create-order
    name: Create Order
    type: traditional
  - id: process-payment
    name: Process Payment
    type: traditional
publishes_events:
  - event: OrderCreated
    from_flow: create-order
  - event: PaymentProcessed
    from_flow: process-payment
  - event: PaymentFailed
    from_flow: process-payment
consumes_events:
  - event: UserRegistered
    handled_by_flow: create-order
    description: Pre-populate user data for new orders
layout:
  flows:
    create-order: { x: 100, y: 100 }
    process-payment: { x: 100, y: 300 }
  portals: {}
```

### specs/domains/orders/flows/create-order.yaml

```yaml
flow:
  id: create-order
  name: Create Order
  type: traditional
  domain: orders
  description: Create a new order from cart items

trigger:
  id: trigger-001
  type: trigger
  position: { x: 250, y: 50 }
  connections:
    - targetNodeId: input-001
  spec:
    event: "HTTP POST /api/v1/orders"
    source: API Gateway
    description: Order creation request
  label: Create Order Request

nodes:
  - id: input-001
    type: input
    position: { x: 250, y: 170 }
    connections:
      - targetNodeId: ds-001
        sourceHandle: "valid"
      - targetNodeId: terminal-validation
        sourceHandle: "invalid"
    spec:
      fields:
        - name: user_id
          type: string
          required: true
        - name: items
          type: array
          required: true
        - name: shipping_address
          type: object
          required: true
        - name: payment_method
          type: string
          required: true
      validation: "user_id must be valid UUID, items must be non-empty array"
      description: Order creation payload
    label: Order Input
    security:
      authentication:
        required: true
        methods: [jwt]

  - id: ds-001
    type: data_store
    position: { x: 250, y: 310 }
    connections:
      - targetNodeId: sc-001
        sourceHandle: "success"
      - targetNodeId: terminal-db-error
        sourceHandle: "error"
    spec:
      operation: create
      model: Order
      data:
        user_id: "$.user_id"
        items: "$.items"
        shipping_address: "$.shipping_address"
        status: "pending"
      description: Save order to database
    label: Save Order

  - id: sc-001
    type: service_call
    position: { x: 250, y: 440 }
    connections:
      - targetNodeId: decision-001
        sourceHandle: "success"
      - targetNodeId: terminal-inventory-error
        sourceHandle: "error"
    spec:
      method: POST
      url: "https://inventory.internal/api/reserve"
      headers:
        Content-Type: application/json
      body:
        order_id: "$.order.id"
        items: "$.items"
      timeout_ms: 5000
      retry:
        max_attempts: 3
        backoff_ms: 1000
      error_mapping:
        "409": "INSUFFICIENT_STOCK"
        "503": "SERVICE_UNAVAILABLE"
      description: Reserve inventory for order items
    label: Reserve Inventory

  - id: decision-001
    type: decision
    position: { x: 250, y: 570 }
    connections:
      - targetNodeId: event-001
        sourceHandle: "true"
      - targetNodeId: terminal-stock-error
        sourceHandle: "false"
    spec:
      condition: inventory.reserved === true
      trueLabel: Reserved
      falseLabel: Out of Stock
      description: Check if inventory was successfully reserved
    label: Inventory Available?

  - id: event-001
    type: event
    position: { x: 150, y: 700 }
    connections:
      - targetNodeId: terminal-success
    spec:
      direction: emit
      event_name: OrderCreated
      payload:
        order_id: "$.order.id"
        user_id: "$.user_id"
        total: "$.order.total"
      async: true
      description: Notify other services that order was created
    label: Emit OrderCreated

  - id: terminal-success
    type: terminal
    position: { x: 150, y: 830 }
    connections: []
    spec:
      outcome: success
      description: Return order object
      status: 201
      body:
        message: "Order created successfully"
        order: "$.order"
    label: Order Created

  - id: terminal-validation
    type: terminal
    position: { x: 450, y: 170 }
    connections: []
    spec:
      outcome: error
      description: Return validation error
      status: 400
      body:
        error: "VALIDATION_ERROR"
        message: "$.validation_errors"
    label: Invalid Input

  - id: terminal-db-error
    type: terminal
    position: { x: 450, y: 310 }
    connections: []
    spec:
      outcome: error
      description: Database write failed
      status: 500
      body:
        error: "INTERNAL_ERROR"
        message: "Failed to create order"
    label: DB Error

  - id: terminal-inventory-error
    type: terminal
    position: { x: 450, y: 440 }
    connections: []
    spec:
      outcome: error
      description: Inventory service unavailable
      status: 503
      body:
        error: "SERVICE_UNAVAILABLE"
        message: "Inventory service temporarily unavailable"
    label: Inventory Service Error

  - id: terminal-stock-error
    type: terminal
    position: { x: 400, y: 700 }
    connections: []
    spec:
      outcome: error
      description: Insufficient stock
      status: 409
      body:
        error: "INSUFFICIENT_STOCK"
        message: "One or more items are out of stock"
    label: Out of Stock

metadata:
  created: "2025-01-10T10:00:00Z"
  modified: "2025-01-10T10:00:00Z"
```

### Agent Flow Example: specs/domains/support/flows/support-ticket.yaml

```yaml
flow:
  id: support-ticket
  name: Support Ticket Handler
  type: agent
  domain: support
  description: AI agent that handles customer support tickets

trigger:
  id: trigger-001
  type: trigger
  position: { x: 250, y: 50 }
  connections:
    - targetNodeId: guard-input
  spec:
    event: "event:SupportTicketCreated"
    source: Ticketing System
    description: New support ticket arrives
  label: New Ticket

nodes:
  - id: guard-input
    type: guardrail
    position: { x: 250, y: 170 }
    connections:
      - targetNodeId: agent-001
    spec:
      position: input
      checks:
        - type: content_policy
          action: block
        - type: prompt_injection
          action: block
      on_block: Reject with policy violation message
    label: Input Guard

  - id: agent-001
    type: agent_loop
    position: { x: 250, y: 320 }
    connections:
      - targetNodeId: gate-001
    spec:
      model: claude-sonnet
      system_prompt: >
        You are a customer support agent. Investigate the issue,
        search the knowledge base, and propose a resolution.
      max_iterations: 8
      temperature: 0.5
      stop_conditions:
        - resolution_proposed
        - escalation_needed
      tools:
        - id: lookup
          name: lookup_ticket
          description: Look up an existing support ticket
          parameters: '{"ticket_id": "string"}'
        - id: search
          name: search_knowledge_base
          description: Search internal KB for solutions
          parameters: '{"query": "string"}'
        - id: resolve
          name: propose_resolution
          description: Propose a resolution for human review
          parameters: '{"resolution": "string"}'
          is_terminal: true
          requires_confirmation: true
      memory:
        - name: conversation
          type: conversation_history
          max_tokens: 8000
          strategy: sliding_window
      on_max_iterations: escalate
    label: Support Agent

  - id: gate-001
    type: human_gate
    position: { x: 250, y: 480 }
    connections:
      - targetNodeId: terminal-001
    spec:
      notification_channels:
        - slack
        - email
      approval_options:
        - id: approve
          label: Approve Resolution
        - id: reject
          label: Reject & Reassign
          requires_input: true
      timeout:
        duration: 1800
        action: escalate
      context_for_human:
        - ticket_summary
        - proposed_resolution
        - customer_history
    label: Escalation Gate

  - id: terminal-001
    type: terminal
    position: { x: 250, y: 600 }
    connections: []
    spec:
      outcome: ticket resolved
      description: Ticket has been resolved
    label: Resolved

metadata:
  created: "2025-01-10T10:00:00Z"
  modified: "2025-01-10T10:00:00Z"
```

---

## 15. Tips for Writing Good Specs

1. **Use descriptive labels** — node labels appear on the canvas and in generated code comments
2. **Fill in all spec fields** — empty specs trigger validation warnings
3. **Connect everything** — no orphaned nodes, all paths must reach a terminal
4. **Use consistent event names** — stick to PascalCase (e.g., `UserRegistered`, `OrderCreated`)
5. **Decision nodes need both branches** — always wire both `true` and `false` handles
6. **Agent flows need terminal tools** — at least one tool must have `is_terminal: true`
7. **Use `flow_ref` format** — sub_flow references should be `domain-id/flow-id`
8. **Node IDs must be unique** within a flow — use a prefix matching the type (e.g., `input-001`, `process-002`)
9. **Position doesn't affect logic** — positions are for canvas layout only, connections define the actual flow
10. **Cross-cutting concerns are optional** — only add observability/security when needed for implementation hints
11. **Always use sourceHandle on branching nodes** — input (valid/invalid), decision (true/false), data_store (success/error), service_call (success/error), loop (body/done), parallel (branch-N/done)
12. **Create supplementary specs early** — system.yaml, architecture.yaml, config.yaml, errors.yaml, and schemas give `/ddd-implement` the context it needs to generate correct code
13. **Use trigger conventions** — prefix with `HTTP`, `cron`, `event:`, `webhook`, or `manual` to communicate trigger type
14. **Add status and body to terminals** — custom fields on terminal specs tell `/ddd-implement` exactly what HTTP response to generate

---

## 16. Design Patterns

Common patterns and conventions for DDD Tool specs.

### HTTP Request/Response Approval

For synchronous approval flows (e.g., "admin approves a pending request"), use an HTTP trigger + decision node — **not** a human_gate. Human gates are for async agent workflows where an AI agent pauses and waits for human review.

```yaml
# Correct: HTTP approval flow
trigger:
  spec:
    event: "HTTP POST /api/requests/{id}/approve"
    source: API Gateway

nodes:
  - type: decision
    spec:
      condition: "user.role === 'admin'"
      trueLabel: Authorized
      falseLabel: Forbidden
    connections:
      - targetNodeId: process-approve
        sourceHandle: "true"
      - targetNodeId: terminal-forbidden
        sourceHandle: "false"
```

### Guardrail Execution Model

Guardrails are **inline and sequential** — they sit in the connection chain and data flows through them in order. They are NOT sidecars or parallel watchers.

```
trigger -> guardrail(input) -> agent_loop -> guardrail(output) -> terminal
```

The input guardrail validates/filters data before it reaches the agent. The output guardrail validates the agent's response before it reaches the user. If a guardrail blocks, the flow stops at that point (see `on_block`).

### Error Routing Convention

For nodes with dual output paths (data_store, service_call, input), the convention is:
- **First connection** = success/happy path
- **Second connection** = error/failure path

Always use explicit `sourceHandle` values for clarity:
- `"success"` / `"error"` for data_store and service_call
- `"valid"` / `"invalid"` for input
- `"true"` / `"false"` for decision

### Conditional Required Fields

Use the `validation` string on input nodes to express conditional requirements:

```yaml
spec:
  fields:
    - name: action
      type: string
      required: true
    - name: reason
      type: string
      required: false
    - name: revised_amount
      type: number
      required: false
  validation: "required_if: action == 'revise' then revised_amount; required_if: action == 'reject' then reason"
```

### Event Cross-Domain Validation

The DDD Tool automatically validates event wiring across domains. You don't need to manually check — just ensure:
- The publishing domain lists the event in `publishes_events` with `from_flow`
- The consuming domain lists it in `consumes_events` with `handled_by_flow`
- The `event` name matches exactly (PascalCase)

The tool will flag errors if a consumed event has no publisher, and warnings if a published event has no consumer.

### Loop with Processing

A loop node iterates over a collection. Use `sourceHandle: "body"` for the loop body path and `sourceHandle: "done"` for after the loop:

```yaml
- id: loop-001
  type: loop
  connections:
    - targetNodeId: process-item
      sourceHandle: "body"
    - targetNodeId: terminal-done
      sourceHandle: "done"
  spec:
    collection: "$.order.items"
    iterator: "item"
    break_condition: "item.status === 'cancelled'"
    description: Process each order item
```

### Parallel with Join

Parallel branches run concurrently. The `branches` field is descriptive only — connections define actual paths:

```yaml
- id: parallel-001
  type: parallel
  connections:
    - targetNodeId: validate-payment
      sourceHandle: "branch-0"
    - targetNodeId: check-inventory
      sourceHandle: "branch-1"
    - targetNodeId: process-continue
      sourceHandle: "done"
  spec:
    branches:
      - "Validate payment method"
      - "Check inventory availability"
    join: all
    timeout_ms: 10000
    description: Run payment and inventory checks in parallel
```
